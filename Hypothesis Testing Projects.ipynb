{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ec8f0f8",
   "metadata": {},
   "source": [
    "Hypothesis Testing Projects "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db787d4",
   "metadata": {},
   "source": [
    "Data Scientist: Inference Specialist\n",
    "Familiar: A Study In Data Analysis\n",
    "Welcome to Familiar, a startup in the new market of blood transfusion! You’ve joined the team because you appreciate the flexible hours and extremely intelligent team, but the overeager doorman welcoming you into the office is a nice way to start your workday (well, work-evening).\n",
    "\n",
    "Familiar has fallen into some tough times lately, so you’re hoping to help them make some insights about their product and help move the needle (so to speak).\n",
    "\n",
    "Note that a solution.py file is also loaded for you in the workspace, which contains solution code for this project. We highly recommend that you complete the project on your own without checking the solution, but feel free to take a look if you get stuck or want to check your answers!\n",
    "\n",
    "Tasks\n",
    "11/13 complete\n",
    "Mark the tasks as complete by checking them off\n",
    "What Can Familiar Do For You?\n",
    "1.\n",
    "The Familiar team has provided us with some data on lifespans for subscribers to two different packages, the Vein Pack and the Artery Pack! This data has been loaded for you as a dataframe named lifespans. Use the .head() method to print out the first five rows and take a look!\n",
    "\n",
    "2.\n",
    "The first thing we want to know is whether Familiar’s most basic package, the Vein Pack, actually has a significant impact on the subscribers. It would be a marketing goldmine if we can show that subscribers to the Vein Pack live longer than other people.\n",
    "\n",
    "Extract the life spans of subscribers to the 'vein' pack and save the data into a variable called vein_pack_lifespans.\n",
    "\n",
    "3.\n",
    "Next, use np.mean() to calculate the average lifespan for Vein Pack subscribers and print the result. Is it longer than 73 years?\n",
    "\n",
    "4.\n",
    "We’d like to find out if the average lifespan of a Vein Pack subscriber is significantly different from the average life expectancy of 73 years.\n",
    "\n",
    "Import the statistical test from scipy.stats that we would use to test the following null and alternative hypotheses:\n",
    "\n",
    "Null: The average lifespan of a Vein Pack subscriber is 73 years.\n",
    "Alternative: The average lifespan of a Vein Pack subscriber is NOT 73 years.\n",
    "5.\n",
    "Now that you’ve imported the function you need, run the significance test and print out the p-value! Is the average lifespan of a Vein Pack subscriber significantly longer than 73 years? Use a significance threshold of 0.05.\n",
    "\n",
    "Upselling Familiar: Pumping Life Into The Company\n",
    "6.\n",
    "In order to differentiate Familiar’s different product lines, we’d like to compare this lifespan data between our different packages. Our next step up from the Vein Pack is the Artery Pack.\n",
    "\n",
    "Let’s get the lifespans of Artery Pack subscribers. Using the same lifespans dataset, extract the lifespans of subscribers to the Artery Pack and save them as artery_pack_lifespans.\n",
    "\n",
    "7.\n",
    "Use np.mean() to calculate the average lifespan for Artery Pack subscribers and print the result. Is it longer than for the Vein Pack?\n",
    "\n",
    "8.\n",
    "We’d like to find out if the average lifespan of a Vein Pack subscriber is significantly different from the average life expectancy for the Artery Pack.\n",
    "\n",
    "Import the statistical test from scipy.stats that we would use to test the following null and alternative hypotheses:\n",
    "\n",
    "Null: The average lifespan of a Vein Pack subscriber is equal to the average lifespan of an Artery Pack subscriber.\n",
    "Alternative: The average lifespan of a Vein Pack subscriber is NOT equal to the average lifespan of an Artery Pack subscriber.\n",
    "9.\n",
    "Now that you’ve imported the function you need, run the significance test and print out the p-value! Is the average lifespan of a Vein Pack subscriber significantly different from the average lifespan of an Artery Pack subscriber? Use a significance threshold of 0.05.\n",
    "\n",
    "Side Effects: A Familiar Problem\n",
    "10.\n",
    "The Familiar team has provided us with another dataset containing survey data about iron counts for our subscribers. This data has been pre-processed to categorize iron counts as “low”, “normal”, and “high” for each subscriber. Familiar wants to be able to advise potential subscribers about possible side effects of these packs and whether they differ for the Vein vs. the Artery pack.\n",
    "\n",
    "The data has been loaded for you as a dataframe named iron. Use the .head() method to print out the first five rows and take a look!\n",
    "\n",
    "11.\n",
    "Is there an association between the pack that a subscriber gets (Vein vs. Artery) and their iron level? Use the pandas crosstab() function to create a contingency table of the pack and iron columns in the iron data. Save the result as Xtab and print it out.\n",
    "\n",
    "12.\n",
    "We’d like to find out if there is a significant association between which pack (Vein vs. Artery) someone subscribes to and their iron level.\n",
    "\n",
    "Import the statistical test from scipy.stats that we would use to test the following null and alternative hypotheses:\n",
    "\n",
    "Null: There is NOT an association between which pack (Vein vs. Artery) someone subscribes to and their iron level.\n",
    "Alternative: There is an association between which pack (Vein vs. Artery) someone subscribes to and their iron level.\n",
    "13.\n",
    "Now that you’ve imported the function you need, run the significance test and print out the p-value! Is there a significant association between which pack (Vein vs. Artery) someone subscribes to and their iron level? Use a significance threshold of 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae7a569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load datasets\n",
    "lifespans = pd.read_csv('familiar_lifespan.csv')\n",
    "iron = pd.read_csv('familiar_iron.csv')\n",
    "\n",
    "# Print lifespan data\n",
    "print(lifespans.head())\n",
    "\n",
    "# Save lifespans for vein pack subscribers\n",
    "vein_pack_lifespans = lifespans.lifespan[lifespans.pack=='vein']\n",
    "\n",
    "# Calculate average lifespan for vein pack\n",
    "print(np.mean(vein_pack_lifespans))\n",
    "\n",
    "# Run one-sample t-test\n",
    "from scipy.stats import ttest_1samp\n",
    "tstat, pval = ttest_1samp(vein_pack_lifespans, 73)\n",
    "print(pval)\n",
    "\n",
    "# Save lifespans for artery pack subscribers\n",
    "artery_pack_lifespans = lifespans.lifespan[lifespans.pack=='artery']\n",
    "\n",
    "# Calculate artery pack life spans\n",
    "print(np.mean(artery_pack_lifespans))\n",
    "\n",
    "# Run two-sample t-test\n",
    "from scipy.stats import ttest_ind\n",
    "tstat, pval = ttest_ind(vein_pack_lifespans, artery_pack_lifespans)\n",
    "print(pval)\n",
    "\n",
    "# Inspect first 5 rows of iron dataset\n",
    "print(iron.head())\n",
    "\n",
    "# Create contingency table\n",
    "Xtab = pd.crosstab(iron.pack, iron.iron)\n",
    "print(Xtab)\n",
    "\n",
    "# Run Chi-Square test\n",
    "from scipy.stats import chi2_contingency\n",
    "chi2, pval, dof, exp = chi2_contingency(Xtab)\n",
    "print(pval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d8eff2",
   "metadata": {},
   "source": [
    "Data Scientist: Inference Specialist\n",
    "FetchMaker\n",
    "Congratulations! You’ve just started working at the hottest new tech startup, FetchMaker. FetchMaker’s mission is to match up prospective dog owners with their perfect pet. FetchMaker has been collecting data on their adoptable dogs, and it’s your job to analyze some of that data.\n",
    "\n",
    "Note that a solution.py file is also loaded for you in the workspace, which contains solution code for this project. We highly recommend that you complete the project on your own without checking the solution, but feel free to take a look if you get stuck or want to check your answers!\n",
    "\n",
    "Tasks\n",
    "11/11 complete\n",
    "Mark the tasks as complete by checking them off\n",
    "Data to the Rescue\n",
    "1.\n",
    "FetchMaker has provided us with data for a sample of dogs from their app, including the following attributes:\n",
    "\n",
    "weight, an integer representing how heavy a dog is in pounds\n",
    "tail_length, a float representing tail length in inches\n",
    "age, in years\n",
    "color, a String such as \"brown\" or \"grey\"\n",
    "is_rescue, a boolean 0 or 1\n",
    "The data has been saved for you as a pandas DataFrame named dogs. Use the .head() method to inspect the first five rows of the dataset.\n",
    "\n",
    "2.\n",
    "FetchMaker estimates (based on historical data for all dogs) that 8% of dogs in their system are rescues.\n",
    "\n",
    "They would like to know if whippets are significantly more or less likely than other dogs to be a rescue.\n",
    "\n",
    "Store the is_rescue values for 'whippet's in a variable called whippet_rescue.\n",
    "\n",
    "3.\n",
    "How many whippets are rescues (remember that the value of is_rescue is 1 for rescues and 0 otherwise)? Save this number as num_whippet_rescues and print it out.\n",
    "\n",
    "4.\n",
    "How many whippets are in this sample of data in total? Save this number as num_whippets and print it out.\n",
    "\n",
    "5.\n",
    "Use a hypothesis test to test the following null and alternative hypotheses:\n",
    "\n",
    "Null: 8% of whippets are rescues\n",
    "Alternative: more or less than 8% of whippets are rescues\n",
    "Save the p-value from this test as pval and print it out. Using a significance threshold of 0.05, Is the proportion of whippets who are rescues significantly different from 8%?\n",
    "\n",
    "Mid-Sized Dog Weights\n",
    "6.\n",
    "Three of FetchMaker’s most popular mid-sized dog breeds are 'whippet's, 'terrier's, and 'pitbull's. Is there a significant difference in the average weights of these three dog breeds?\n",
    "\n",
    "To start answering this question, save the weights of each of these breeds in three separate series named wt_whippets, wt_terriers, and wt_pitbulls, respectively.\n",
    "\n",
    "7.\n",
    "Run a single hypothesis test to address the following null and alternative hypotheses:\n",
    "\n",
    "Null: whippets, terriers, and pitbulls all weigh the same amount on average\n",
    "Alternative: whippets, terriers, and pitbulls do not all weigh the same amount on average (at least one pair of breeds has differing average weights)\n",
    "Save the resulting p-value as pval and print it out. Using a significance threshold of 0.05, is there at least one pair of dog breeds that have significantly different average weights?\n",
    "\n",
    "8.\n",
    "If you completed the previous step correctly, you should have concluded that at least one pair of dog breeds have significantly different average weights.\n",
    "\n",
    "Run another hypothesis test to determine which of those breeds (whippets, terriers, and pitbulls) weigh different amounts on average. Use an overall type I error rate of 0.05 for all three comparisons. Note that we’ve already provided you with code in script.py to subset the data to just these breeds and have saved this subset as dogs_wtp using the following code:\n",
    "\n",
    "dogs_wtp = dogs[dogs.breed.isin(['whippet', 'terrier', 'pitbull'])]\n",
    "\n",
    "Copy to Clipboard\n",
    "\n",
    "This should make it easier for you to run the test you need!\n",
    "\n",
    "Print out the results. Which pairs of dog breeds weigh different amounts?\n",
    "\n",
    "Poodle and Shihtzu Colors\n",
    "9.\n",
    "FetchMaker wants to know if 'poodle's and 'shihtzu's come in different colors. Note that we’ve already provided you with code in script.py to subset the data to just these breeds and have saved this subset as dogs_ps using the following code:\n",
    "\n",
    "dogs_ps = dogs[dogs.breed.isin(['poodle', 'shihtzu'])]\n",
    "\n",
    "Copy to Clipboard\n",
    "\n",
    "This should make it easier for you to investigate this question!\n",
    "\n",
    "To start, use the subsetted data to create a contingency table of dog colors by breed (poodle vs. shihtzu). Save the table as Xtab and print it out.\n",
    "\n",
    "10.\n",
    "Run a hypothesis test for the following null and alternative hypotheses:\n",
    "\n",
    "Null: There is an association between breed (poodle vs. shihtzu) and color.\n",
    "Alternative: There is not an association between breed (poodle vs. shihtzu) and color.\n",
    "Save the p-value as pval and print it out. Do poodles and shihtzus come in significantly different color combinations? Use a significance threshold of 0.05.\n",
    "\n",
    "Good learner! Have a treat!\n",
    "11.\n",
    "Great job!\n",
    "\n",
    "Feel free to play around with the FetchMaker data some more and run some hypothesis tests of your own.\n",
    "\n",
    "The breeds you can explore are \"poodle\", \"rottweiler\", \"whippet\", \"greyhound\", \"terrier\", \"chihuahua\", \"shihtzu\", and \"pitbull\".\n",
    "\n",
    "Extra challenge: Remind yourself of your data visualization skills and your ability to describe the central tendency of the data. For example, a boxplot visualization can add a lot to your understanding of an ANOVA result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef292bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import codecademylib3\n",
    "\n",
    "# Import data\n",
    "dogs = pd.read_csv('dog_data.csv')\n",
    "\n",
    "# Inspect first few rows of data\n",
    "print(dogs.head())\n",
    "\n",
    "# Save the is_rescue column for whippets\n",
    "whippet_rescue = dogs.is_rescue[dogs.breed == 'whippet']\n",
    "\n",
    "# Calculate and print the number of whippet rescues\n",
    "num_whippet_rescues = np.sum(whippet_rescue == 1)\n",
    "print(num_whippet_rescues)\n",
    "\n",
    "# Calculate and print the number of whippets\n",
    "num_whippets = len(whippet_rescue)\n",
    "print(num_whippets)\n",
    "\n",
    "# Run a binomial test \n",
    "from scipy.stats import binom_test\n",
    "pval = binom_test(num_whippet_rescues, num_whippets, .08)\n",
    "print(pval)\n",
    "\n",
    "# Save the weights of whippets, terriers, and pitbulls\n",
    "wt_whippets = dogs.weight[dogs.breed == 'whippet']\n",
    "wt_terriers = dogs.weight[dogs.breed == 'terrier']\n",
    "wt_pitbulls = dogs.weight[dogs.breed == 'pitbull']\n",
    "\n",
    "# Run an ANOVA \n",
    "from scipy.stats import f_oneway\n",
    "Fstat, pval = f_oneway(wt_whippets, wt_terriers, wt_pitbulls)\n",
    "print(pval)\n",
    "\n",
    "# Subset to just whippets, terriers, and pitbulls\n",
    "dogs_wtp = dogs[dogs.breed.isin(['whippet', 'terrier', 'pitbull'])]\n",
    "\n",
    "# Run Tukey's Range Test\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "output = pairwise_tukeyhsd(dogs_wtp.weight, dogs_wtp.breed)\n",
    "print(output)\n",
    "\n",
    "# Subset to just poodles and shihtzus\n",
    "dogs_ps = dogs[dogs.breed.isin(['poodle', 'shihtzu'])]\n",
    "\n",
    "# Create a contingency table of color vs. breed\n",
    "Xtab = pd.crosstab(dogs_ps.color, dogs_ps.breed)\n",
    "print(Xtab)\n",
    "\n",
    "# Run a Chi-Square Test\n",
    "from scipy.stats import chi2_contingency\n",
    "chi2, pval, dof, exp = chi2_contingency(Xtab)\n",
    "print(pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32493a0",
   "metadata": {},
   "source": [
    "Data Scientist: Inference Specialist\n",
    "Analyzing Farmburg's A/B Test\n",
    "Brian is a Product Manager at FarmBurg, a company that makes a farming simulation social network game. In the FarmBurg game, you can plow, plant, and harvest different crops. ​Brian has been conducting an A/B Test with three different variants, and he wants you to help him analyze the results. Using the Python modules pandas and SciPy, you will help him make some important business decisions!\n",
    "\n",
    "Note that a solution.py file is also loaded for you in the workspace, which contains solution code for this project. We highly recommend that you complete the project on your own without checking the solution, but feel free to take a look if you get stuck or want to check your answers!\n",
    "\n",
    "Tasks\n",
    "12/13 complete\n",
    "Mark the tasks as complete by checking them off\n",
    "Project Requirements\n",
    "1.\n",
    "Brian ran an A/B test with three different groups: A, B, and C. He has provided us with a CSV file of his results named clicks.csv. It has the following columns:\n",
    "\n",
    "user_id: a unique id for each visitor to the FarmBurg site\n",
    "group: either 'A', 'B', or 'C' depending on which group the visitor was assigned to\n",
    "is_purchase: either 'Yes' if the visitor made a purchase or 'No' if they did not.\n",
    "We’ve already imported pandas as pd and loaded clicks.csv as abdata. Inspect the data using the .head() method.\n",
    "\n",
    "2.\n",
    "Note that we have two categorical variables: group and is_purchase. We are interested in whether visitors are more likely to make a purchase if they are in any one group compared to the others. Because we want to know if there is an association between two categorical variables, we’ll start by using a Chi-Square test to address our question.\n",
    "\n",
    "In order to run a Chi-Square test, we first need to create a contingency table of the variables group and is_purchase. Use pd.crosstab() to create this table and name the result Xtab, then print it out. Which group appears to have the highest number of purchases?\n",
    "\n",
    "3.\n",
    "To conduct the Chi-Square Test, import chi2_contingency from scipy.stats.\n",
    "\n",
    "Then, use the function chi2_contingency with the data in Xtab to calculate the p-value. Remember that of the four values returned by chi2_contingency, the p-value is the second value.\n",
    "\n",
    "Save the p-value to a variable named pval and print the result. Using a significance threshold of 0.05, is there a significant difference in the purchase rate for groups A, B, and C?\n",
    "\n",
    "Note that you might see a number in scientific notation. For example, 1.234e-8 is equal to 0.00000001234 (we move the decimal to the left by 8 places and insert zeros).\n",
    "\n",
    "4.\n",
    "Our day is a little less busy than expected, so we decide to ask Brian about his test.\n",
    "\n",
    "Us: Hey Brian! What was that test you were running anyway?\n",
    "\n",
    "Brian: We are trying to get users to purchase a small FarmBurg upgrade package. It’s called a microtransaction. We’re not sure how much to charge for it, so we tested three different price points: $0.99 (group 'A'), $1.99 (group 'B'), and $4.99 (group 'C'). It looks like significantly more people bought the upgrade package for $0.99, so I guess that’s what we’ll charge.\n",
    "\n",
    "Us: Oh no! We should have asked you this before we did that Chi-Square test. That wasn’t the right test at all. It’s true that more people wanted to purchase the upgrade at $0.99; you probably expected that. What we really want to know is whether each price point allows us to make enough money that we can exceed some target goal. Brian, how much do you think it cost to build this feature?\n",
    "\n",
    "Brian: Hmm. I guess that we need to generate a minimum of $1000 in revenue per week in order to justify this project.\n",
    "\n",
    "Us: We have some work to do!\n",
    "\n",
    "In order to justify this feature, we will need to calculate the necessary purchase rate for each price point. Let’s start by calculating the number of visitors to the site this week.\n",
    "\n",
    "It turns out that Brian ran his original test over the course of a week, so the number of visitors in abdata is equal to the number of visitors in a typical week. Calculate the number of visitors in the data and save the value in a variable named num_visits. Make sure to print the value.\n",
    "\n",
    "5.\n",
    "Now that we know how many visitors we generally get each week (num_visits), we need to calculate the number of visitors who would need to purchase the upgrade package at each price point ($0.99, $1.99, $4.99) in order to generate Brian’s minimum revenue target of $1,000 per week.\n",
    "\n",
    "To start, calculate the number of sales that would be needed to reach $1,000 dollars of revenue at a price point of $0.99. Save the result as num_sales_needed_099 and print it out.\n",
    "\n",
    "6.\n",
    "Now that we know how many sales we need at a $0.99 price point, calculate the proportion of weekly visitors who would need to make a purchase in order to meet that goal. Remember that the number of weekly visitors is saved as num_visits. Save the result as p_sales_needed_099 and print it out.\n",
    "\n",
    "7.\n",
    "Repeat the steps from tasks 5 and 6 for the other price points ($1.99 and $4.99). Save the number of sales needed for each price point as num_sales_needed_199 and num_sales_needed_499, respectively. Then, save the proportion of visits needed as p_sales_needed_199 and p_sales_needed_499, respectively.\n",
    "\n",
    "Print out the proportions. Note that for higher price points, you’ll need to sell fewer upgrade packages in order to meet your minimum revenue target — so the proportions should decrease as the price points increase.\n",
    "\n",
    "8.\n",
    "Now let’s return to Brian’s question. To start, we want to know if the percent of Group A (the $0.99 price point) that purchased an upgrade package is significantly greater than p_sales_needed_099 (the percent of visitors who need to buy an upgrade package at $0.99 in order to make our minimum revenue target of $1,000).\n",
    "\n",
    "To answer this question, we want to focus on just the visitors in group A. Then, we want to compare the number of purchases in that group to p_sales_needed_099.\n",
    "\n",
    "Since we have a single sample of categorical data and want to compare it to a hypothetical population value, a binomial test is appropriate. In order to run a binomial test for group A, we need to know two pieces of information:\n",
    "\n",
    "The number of visitors in group A (the number of visitors who were offered the $0.99 price point)\n",
    "The number of visitors in Group A who made a purchase\n",
    "Calculate these two numbers and save them as samp_size_099 and sales_099, respectively. Note that you can use the contingency table that you printed earlier to get these numbers OR you can use Python syntax.\n",
    "\n",
    "9.\n",
    "Calculate the sample size and number of purchases in group B (the $1.99 price point) and save them as samp_size_199 and sales_199, respectively. Then do the same for group C (the $4.99 price point) and save them as samp_size_499 and sales_499, respectively.\n",
    "\n",
    "10.\n",
    "For Group A ($0.99 price point), perform a binomial test using binom_test() to see if the observed purchase rate is significantly greater than p_sales_needed_099. Remember that there are four inputs to binom_test():\n",
    "\n",
    "x will be the number of purchases for Group A\n",
    "n will be the total number of visitors assigned group A\n",
    "p will be the target percent of purchases for the $0.99 price point\n",
    "alternative will indicate the alternative hypothesis for this test; in this case, we want to know if the observed purchase rate is significantly 'greater' than the purchase rate that results in the minimum revenue target.\n",
    "Save the results to pvalueA, and print its value. Note that you’ll first need to import the binom_test() function from scipy.stats using the following line of code:\n",
    "\n",
    "from scipy.stats import binom_test\n",
    "\n",
    "Copy to Clipboard\n",
    "\n",
    "11.\n",
    "For Group B ($1.99 price point), perform a binomial test to see if the observed purchase rate is significantly greater than p_sales_needed_199.\n",
    "\n",
    "Save the results to pvalueB, and print its value.\n",
    "\n",
    "12.\n",
    "For Group C ($4.99 price point), perform a binomial test to see if the observed purchase rate is significantly greater than p_sales_needed_499.\n",
    "\n",
    "Save the results to pvalueC, and print its value.\n",
    "\n",
    "13.\n",
    "Based on the three p-values you calculated for the binomial tests in each group and a significance threshold of 0.05, were there any groups where the purchase rate was significantly higher than the target? Based on this information, what price should Brian charge for the upgrade package?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06daeabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import codecademylib3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read in the `clicks.csv` file as `abdata`\n",
    "abdata = pd.read_csv('clicks.csv')\n",
    "\n",
    "# Inspect the dataframe\n",
    "print(abdata.head())\n",
    "\n",
    "# Create a contingency table with pd.crosstab\n",
    "Xtab = pd.crosstab(abdata.group, abdata.is_purchase)\n",
    "\n",
    "# Print the contingency table\n",
    "print(Xtab)\n",
    "\n",
    "# Import chi2_contingency module\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Calculate the p-value\n",
    "chi2, pval, dof, expected = chi2_contingency(Xtab)\n",
    "\n",
    "# Print the p-value\n",
    "print(pval)\n",
    "\n",
    "# Determine if the p-value is significant\n",
    "is_significant = True\n",
    "\n",
    "# Calculate and print the number of visits\n",
    "num_visits = len(abdata)\n",
    "\n",
    "# Print the number of visits\n",
    "print(num_visits)\n",
    "\n",
    "# Calculate the purchase rate needed at 0.99\n",
    "num_sales_needed_099 = 1000/0.99\n",
    "p_sales_needed_099 = num_sales_needed_099/num_visits\n",
    "\n",
    "# Print the purchase rate needed at 0.99\n",
    "print(p_sales_needed_099)\n",
    "\n",
    "# Calculate the purchase rate needed at 1.99\n",
    "num_sales_needed_199 = 1000/1.99\n",
    "p_sales_needed_199 = num_sales_needed_199/num_visits\n",
    "\n",
    "# Print the purchase rate needed at 1.99\n",
    "print(p_sales_needed_199)\n",
    "\n",
    "# Calculate the purchase rate needed at 4.99\n",
    "num_sales_needed_499 = 1000/4.99\n",
    "p_sales_needed_499 = num_sales_needed_499/num_visits\n",
    "\n",
    "# Print the purchase rate needed at 4.99\n",
    "print(p_sales_needed_499)\n",
    "\n",
    "# Calculate samp size & sales for 0.99 price point\n",
    "samp_size_099 = np.sum(abdata.group == 'A')\n",
    "sales_099 = np.sum((abdata.group == 'A') & (abdata.is_purchase == 'Yes'))\n",
    "\n",
    "# Print samp size & sales for 0.99 price point\n",
    "print(samp_size_099)\n",
    "print(sales_099)\n",
    "\n",
    "# Calculate samp size & sales for 1.99 price point\n",
    "samp_size_199 = np.sum(abdata.group == 'B')\n",
    "sales_199 = np.sum((abdata.group == 'B') & (abdata.is_purchase == 'Yes'))\n",
    "\n",
    "# Print samp size & sales for 1.99 price point\n",
    "print(samp_size_199)\n",
    "print(sales_199)\n",
    "\n",
    "# Calculate samp size & sales for 4.99 price point\n",
    "samp_size_499 = np.sum(abdata.group == 'C')\n",
    "sales_499 = np.sum((abdata.group == 'C') & (abdata.is_purchase == 'Yes'))\n",
    "\n",
    "# Print samp size & sales for 4.99 price point\n",
    "print(samp_size_499)\n",
    "print(sales_499)\n",
    "\n",
    "# Import the binom_test module\n",
    "from scipy.stats import binom_test\n",
    "\n",
    "# Calculate the p-value for Group A\n",
    "pvalueA = binom_test(sales_099, n=samp_size_099, p=p_sales_needed_099, alternative='greater')\n",
    "\n",
    "# Print the p-value for Group A\n",
    "print(pvalueA)\n",
    "\n",
    "# Calculate the p-value for Group B\n",
    "pvalueB = binom_test(sales_199, n=samp_size_199, p=p_sales_needed_199, alternative='greater')\n",
    "\n",
    "# Print the p-value for Group B\n",
    "print(pvalueB)\n",
    "\n",
    "# Calculate the p-value for Group C\n",
    "pvalueC = binom_test(sales_499, n=samp_size_499, p=p_sales_needed_499, alternative='greater')\n",
    "\n",
    "# Print the p-value for Group C\n",
    "print(pvalueC)\n",
    "\n",
    "# Set the correct value for the final answer variable\n",
    "final_answer = '4.99'\n",
    "\n",
    "# Print the chosen price group\n",
    "print(final_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
